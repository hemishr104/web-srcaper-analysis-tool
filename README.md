# Project Overview

-----

This project involves web scraping book data from a website, cleaning and analyzing the data, and then visualizing the results. The goal is to extract product information, process it, and generate insights into book prices.

## Files

  * **WebSracper.py**: A Python script that uses `requests` and `BeautifulSoup` to scrape book names and prices from `books.toscrape.com`. The scraped data is saved to an Excel file named **products.xlsx**.
  * **Analysis.ipynb**: A Jupyter Notebook that performs the data cleaning, analysis, and visualization.
  * **products.xlsx**: The raw data file generated by the web scraping script. It contains the book titles and their prices, which include currency symbols.
  * **product\_cleaned.csv**: The cleaned data file created after removing currency symbols and converting the 'Price' column to a numerical format.
  * **price\_distribution\_pie\_chart.png**: A pie chart visualizing the distribution of book prices into different categories (e.g., green, orange, red).
  * **top\_10\_expensive\_books.png**: A bar chart showing the top 10 most expensive books from the dataset.

-----

## Analysis and Visualizations

The **Analysis.ipynb** notebook performs the following steps:

1.  **Data Loading**: The **products.xlsx** file is loaded into a pandas DataFrame.
2.  **Data Cleaning**: The 'Price' column is cleaned by removing the 'Â£' symbol and converting the values to a float data type. The cleaned data is then saved to a new CSV file, **product\_cleaned.csv**.
3.  **Data Categorization**: Books are categorized into three price groups: 'green' (low price), 'orange' (medium price), and 'red' (high price).
4.  **Data Visualization**:
      * A pie chart (**price\_distribution\_pie\_chart.png**) is generated to show the percentage of books in each price category.
      * A bar chart (**top\_10\_expensive\_books.png**) is created to display the 10 books with the highest prices.

-----

## How to Use

  * **Scrape Data**: Run the **WebSracper.py** script to get the latest data and save it as **products.xlsx**.

    ```bash
    python WebSracper.py
    ```

  * **Analyze Data**: Open the **Analysis.ipynb** notebook in a Jupyter environment to run the data cleaning and analysis steps. The notebook will generate the cleaned CSV file and the two chart images.

    ```bash
    jupyter notebook Analysis.ipynb
    ```

-----

## Libraries Used

  * `pandas`
  * `requests`
  * `BeautifulSoup`
  * `matplotlib.pyplot`
